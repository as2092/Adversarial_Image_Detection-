{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms, utils\n",
    "from network.cnn_net import cnn_net\n",
    "from sklearn.decomposition import PCA\n",
    "import utils.mnist_loader as mnist_loader\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import argparse\n",
    "from numpy import ma\n",
    "import scipy\n",
    "import os.path\n",
    "import network.ann_net as ann_net\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "\n",
    "def gn_adv(args, model, device, target):\n",
    "    \"\"\"\n",
    "\n",
    "    :param args:\n",
    "    :param model:\n",
    "    :param device:\n",
    "    :param target: label for which adv image is to be generated\n",
    "    :return: adv image\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    target = torch.Tensor([target]).long()\n",
    "    data = torch.rand((1, 1, 28, 28), requires_grad=True, device=device)\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    optimizer = optim.SGD([data], lr=1, momentum=args.momentum)\n",
    "\n",
    "    for itr in range(50):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        #print(loss)\n",
    "        optimizer.step()\n",
    "\n",
    "    return torch.squeeze(data).detach().cpu().numpy()\n",
    "\n",
    "\n",
    "def sneaky_adv(args, model, device, img, target, lmbd):\n",
    "    \"\"\"\n",
    "    :param img: image whose alike image to be constructed\n",
    "    :param target: label that network should output\n",
    "    :return: image that looks like img and network output is target\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    data = torch.rand((1, 1, 28, 28), device=device, requires_grad=True)\n",
    "    target = torch.Tensor([target]).long()\n",
    "    img = torch.Tensor(img).view((1, 1, 28, 28))\n",
    "    img, target, data = img.to(device), target.to(device), data.to(device)\n",
    "    optimizer = optim.SGD([data], lr=0.5, momentum=args.momentum)\n",
    "\n",
    "    for itr in range(300):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target) + lmbd*torch.norm((img-data), 2)\n",
    "        loss.backward()\n",
    "        #print(loss)\n",
    "        optimizer.step()\n",
    "\n",
    "    return torch.squeeze(data).detach().cpu().numpy()\n",
    "    \n",
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                       100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "\n",
    "def test(args, model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "\n",
    "def kld(model, actual):\n",
    "    \"\"\"\n",
    "    model : its the array that is input to the network\n",
    "    actual : image corresponding to the network output\n",
    "    return: KL divergence between two prob distributions\n",
    "    \"\"\"\n",
    "    model = np.asarray(list(model) + [0 for i in range(255 - len(model))])\n",
    "    actual = np.asarray(list(actual) + [0 for i in range(255 - len(actual))])\n",
    "    k = ((model * np.log(model)) - (model * np.log(actual))).sum()\n",
    "    print(k)\n",
    "    # k = (model * ma.log(model/actual)).sum()\n",
    "\n",
    "    return k\n",
    "\n",
    "\n",
    "def mean_image(tr_data):\n",
    "    \"\"\"\n",
    "\n",
    "    :param tr_data: input mnist data\n",
    "    :return: mean images for each class\n",
    "    \"\"\"\n",
    "    val = {}\n",
    "    for i in range(10):\n",
    "        mat = []\n",
    "        for r in range(len(tr_data)):\n",
    "            if tr_data[r][1][i] == 1:\n",
    "                x = tr_data[r][0]\n",
    "                mat.append(np.asarray(x))\n",
    "        val[i] = np.mean(mat, axis=0) * (100)\n",
    "\n",
    "    return val\n",
    "\n",
    "\n",
    "def gn_idx_list(training_data):\n",
    "    idx_list = {}\n",
    "    for i in range(10):\n",
    "        idx_list[i] = []\n",
    "    for i in range(len(training_data)):\n",
    "        idx_list[np.argmax(training_data[i][1])].append(i)\n",
    "\n",
    "    return idx_list    \n",
    "\n",
    "\n",
    "\n",
    "def gn_adv_imgs(args, model, device, training_data):\n",
    "    \"\"\"\n",
    "\n",
    "    :param training_data:\n",
    "    :return: 100 adversarial images\n",
    "    \"\"\"\n",
    "    gn = {}\n",
    "    \"\"\"idx_list = []\n",
    "    for i in range(10):\n",
    "        idx = np.random.randint(0, 8000)\n",
    "        while training_data[idx][1][i] != 1:\n",
    "            idx += 1\n",
    "        idx_list.append(idx)\"\"\"\n",
    "    idx_list = gn_idx_list(training_data)\n",
    "\n",
    "    for g in range(10):\n",
    "        gl = []\n",
    "        print(g)\n",
    "        for v in range(10):\n",
    "            if g != v:\n",
    "                for i in range(4):\n",
    "                    idx = idx_list[v][i]\n",
    "                    gl.append(sneaky_adv(args, model, device, training_data[idx][0], g, 0.4))\n",
    "            else:\n",
    "                for i in range(4):\n",
    "                    idx = idx_list[v][i]\n",
    "                    gl.append(gn_adv(args, model, device, g))\n",
    "        gn[g] = gl\n",
    "\n",
    "    return gn\n",
    "\n",
    "\n",
    "def gn_pd_imgs(adv_imgs):\n",
    "    \"\"\"\n",
    "    adv_imgs: a dictionary with keys as the classes and corresponding adv images as values\n",
    "    returns gn_pd : a dictionary with keys as classes and corresponding prob. distribution of adv images\n",
    "    \"\"\"\n",
    "    gn_pd = {}\n",
    "    for k, v in adv_imgs.items():\n",
    "        bin_y = []\n",
    "\n",
    "        for i in range(len(v)):\n",
    "            bin_y.append(generate_pd(v[i]))\n",
    "\n",
    "        gn_pd[k] = bin_y\n",
    "\n",
    "    return gn_pd\n",
    "\n",
    "\n",
    "def mean_pd(mean_imgs):\n",
    "    \"\"\"\n",
    "    val: a dictionary with keys as the classes and corresponding mean images as values\n",
    "    returns val_pd : a dictionary with keys as classes and corresponding prob. distribution of mean images\n",
    "    \"\"\"\n",
    "    val_pd = {}\n",
    "    for k, v in mean_imgs.items():\n",
    "        # print(k)\n",
    "        # print(len(v))\n",
    "        val_pd[k] = generate_pd(v)\n",
    "\n",
    "    return val_pd\n",
    "\n",
    "\n",
    "def generate_pd(img, patch_size=28):\n",
    "    \"\"\"\n",
    "    img: an image\n",
    "    returns pd : prob distribution of intensities in img\n",
    "    \"\"\"\n",
    "    \n",
    "    if img.max() - img.min() == 0:\n",
    "        img = np.zeros((patch_size, patch_size))\n",
    "    else:\n",
    "        img = ((img - img.min()) * (1 / (img.max() - img.min()) * 255).astype('uint8'))\n",
    "    img = np.floor(img)\n",
    "    img = img.reshape((-1, patch_size**2))\n",
    "    img = img.astype('int64')\n",
    "    bin_m = np.bincount(img[0])\n",
    "    l1 = list(bin_m)\n",
    "    l2 = [0]*(256 - len(bin_m))\n",
    "    bin_m = l1 + l2\n",
    "    bin_m = [x if x != 0 else 0.0001 for x in bin_m] \n",
    "    bin_m = bin_m / sum(bin_m)\n",
    "    # making sure to have len of list 255\n",
    "    pd = np.asarray(bin_m)\n",
    "    #pd = [x if x != 0 else 0.0001 for x in pd]  # to avoid divide by zero in KLD\n",
    "\n",
    "    return pd\n",
    "\n",
    "\n",
    "\n",
    "def kl_calc(adv_im, mean_im):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    adv_im = np.asarray(adv_im).reshape(28, 28)\n",
    "    mean_im = np.asarray(mean_im).reshape(28, 28)\n",
    "    k_sum = 0\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            s_arr = adv_im[i: i + 7, i: i + 7]\n",
    "            p = generate_pd(s_arr, 7)\n",
    "            # mean image pd\n",
    "            ms_arr = mean_im[i: i + 7, i: i + 7]\n",
    "            q = generate_pd(ms_arr, 7)\n",
    "            k_sum += scipy.stats.entropy(p, q)\n",
    "\n",
    "    return k_sum\n",
    "\n",
    "def js_calc(adv_im, mean_im):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    adv_im = np.asarray(adv_im).reshape(28, 28)\n",
    "    mean_im = np.asarray(mean_im).reshape(28, 28)\n",
    "    k_sum = 0\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            s_arr = adv_im[i: i + 7, j: j + 7]\n",
    "            p = generate_pd(s_arr, 7)\n",
    "            # mean image pd\n",
    "            ms_arr = mean_im[i: i + 7, j: j + 7]\n",
    "            q = generate_pd(ms_arr, 7)\n",
    "            r = (p + q)/ 2\n",
    "            k_sum += (scipy.stats.entropy(p, r) / 2) + (scipy.stats.entropy(q, r) / 2)\n",
    "\n",
    "    return k_sum\n",
    "\n",
    "def ac_calc(test_data, training_data, adv_imgs, mean_imgs, min_thr, fun):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    min_thr = min_thr_calc(adv_imgs, mean_imgs, fun)\n",
    "    \n",
    "    success = 0\n",
    "    tmp = 1000\n",
    "    for i in range(len(adv_imgs)):\n",
    "        f = adv_imgs[i]\n",
    "        for j in range(len(f)):\n",
    "            tmp = fun(f[j],mean_imgs[i])\n",
    "            if tmp >= min_thr[i]:\n",
    "                success += 1\n",
    "\n",
    "    #print((success/40000) * 100)\n",
    "    #success = 0\n",
    "    tmp = 1000\n",
    "    for i in range(400):\n",
    "        label = np.argmax(test_data[i][1])\n",
    "        f = np.asarray(test_data[i][0]).reshape((-1, 784))\n",
    "        tmp = fun(f, mean_imgs[label])\n",
    "        if tmp < min_thr[label]:\n",
    "            success += 1\n",
    "    '''\n",
    "    for i in range(len(training_data)):\n",
    "        label = np.argmax(training_data[i][1])\n",
    "        f = np.asarray(training_data[i][0]).reshape((-1, 784))\n",
    "        tmp = fun(f, mean_imgs[label])\n",
    "        if tmp < min_thr[label]:\n",
    "            success += 1\n",
    "'''\n",
    "    return (success/(len(adv_imgs)*len(adv_imgs[0]) + 400)* 100)\n",
    "\n",
    "\n",
    "def min_thr_calc(adv_imgs, mean_imgs, fun):\n",
    "    \"\"\"\n",
    "    # each class contain 4000 adversarial examples\n",
    "    # 400 uniformly chosen samples out of 4000 are used for min_thr calc\n",
    "    return: list containing min_thr for each of the 10 classes\n",
    "    \"\"\"\n",
    "    min_thr = []\n",
    "    ind = np.random.randint(40, size=4)\n",
    "    tmp = 1000\n",
    "    for i in range(len(adv_imgs)):\n",
    "        f = adv_imgs[i]\n",
    "        for j in ind:\n",
    "            tmp = min(tmp, fun(f[j], mean_imgs[i]))\n",
    "        if (tmp == 1000):\n",
    "            print(i)\n",
    "        min_thr.append(tmp) \n",
    "        tmp =1000\n",
    "    \n",
    "    return min_thr\n",
    "\n",
    "def show_images(images, cols = 1, titles = None):\n",
    "    \"\"\"Display a list of images in a single figure with matplotlib.\n",
    "    \n",
    "    Parameters\n",
    "    ---------\n",
    "    images: List of np.arrays compatible with plt.imshow.\n",
    "    \n",
    "    cols (Default = 1): Number of columns in figure (number of rows is \n",
    "                        set to np.ceil(n_images/float(cols))).\n",
    "    \n",
    "    titles: List of titles corresponding to each image. Must have\n",
    "            the same length as titles.\n",
    "    \"\"\"\n",
    "    assert((titles is None)or (len(images) == len(titles)))\n",
    "    n_images = len(images)\n",
    "    if titles is None: titles = ['Image (%d)' % i for i in range(0,n_images)]\n",
    "    fig = plt.figure(frameon=False)\n",
    "    for n, (image, title) in enumerate(zip(images, titles)):\n",
    "        \n",
    "        #a = fig.add_subplot(cols, np.ceil(n_images/float(cols)), n + 1)\n",
    "        a = fig.add_subplot(cols, np.ceil(n_images/float(1)), n + 1)\n",
    "        if image.ndim == 2:\n",
    "            plt.gray()\n",
    "        plt.axis('off')    \n",
    "        plt.imshow(image)\n",
    "        a.set_title(title)\n",
    "    fig.set_size_inches(np.array(fig.get_size_inches()) * n_images)\n",
    "    fig.savefig('out.png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_exist\n",
      "4000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'fig = plt.figure()\\nax1 = fig.add_subplot(111)\\n\\nax1.scatter(tr_l, np.zeros((len(tr_l))), s=10, c=\\'b\\', marker=\"s\", label=\\'train\\')\\nax1.scatter(ad_l, np.ones((len(ad_l))), s=10, c=\\'r\\', marker=\"o\", label=\\'adversarial\\')\\nplt.legend(loc=\\'upper left\\');\\nplt.show()\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#def main():\n",
    "    # Training settings\n",
    "parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n",
    "parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n",
    "                    help='input batch size for training (default: 64)')\n",
    "parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\n",
    "                    help='input batch size for testing (default: 1000)')\n",
    "parser.add_argument('--epochs', type=int, default=10, metavar='N',\n",
    "                    help='number of epochs to train (default: 10)')\n",
    "parser.add_argument('--lr', type=float, default=0.1, metavar='LR',\n",
    "                    help='learning rate (default: 0.01)')\n",
    "parser.add_argument('--momentum', type=float, default=0.5, metavar='M',\n",
    "                    help='SGD momentum (default: 0.5)')\n",
    "parser.add_argument('--no-cuda', action='store_true', default=True,\n",
    "                    help='disables CUDA training')\n",
    "parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                    help='random seed (default: 1)')\n",
    "parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
    "                    help='how many batches to wait before logging training status')\n",
    "\n",
    "parser.add_argument('--save-model', action='store_true', default=False,\n",
    "                    help='For Saving the current Model')\n",
    "args = parser.parse_args([])\n",
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data/mnist_digit', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data/mnist_digit', train=False, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])),\n",
    "    batch_size=args.test_batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "\n",
    "model = cnn_net().to(device)\n",
    "optimizer = None\n",
    "\n",
    "# for training of the cnn-network\n",
    "if (args.save_model):\n",
    "    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        train(args, model, device, train_loader, optimizer, epoch)\n",
    "        test(args, model, device, test_loader)\n",
    "\n",
    "    torch.save(model.state_dict(), \"mnist_cnn.pt\")\n",
    "\n",
    "# to generate adversarial images from trained network\n",
    "model.load_state_dict(torch.load(\"mnist_cnn.pt\"))\n",
    "model.eval()\n",
    "\n",
    "training_data, validation_data, test_data = mnist_loader.load_data_wrapper()\n",
    "training_data = list(training_data)\n",
    "test_data = list(test_data)\n",
    "\n",
    "'''for target in range(10):\n",
    "    res = gn_adv(args, model, device, target)\n",
    "    res = torch.Tensor(res).reshape(1, 1, 28, 28)\n",
    "    output = model(res)\n",
    "    pred = output.argmax(dim=1, keepdim=True)\n",
    "    print(pred)\n",
    "\n",
    "# generate sneaky_adversarial images test code\n",
    "target_label = 1\n",
    "target_img = 4\n",
    "idx = np.random.randint(0, 8000)\n",
    "while training_data[idx][1][target_img] != 1:\n",
    "    idx += 1\n",
    "#training_data[idx][0]\n",
    "res = sneaky_adv(args, model, device, training_data[idx][0], target_label, 0.4)'''\n",
    "\n",
    "# generate adversarial images\n",
    "if os.path.exists('adv_imgs.pkl'):\n",
    "    print(\"file_exist\")\n",
    "    with open('adv_imgs.pkl', 'rb') as f:\n",
    "        adv_imgs = pickle.load(f)\n",
    "else:\n",
    "    adv_imgs = gn_adv_imgs(args, model, device, training_data)\n",
    "    with open(\"adv_imgs.pkl\", \"wb\") as fp:   #Pickling\n",
    "        pickle.dump(adv_imgs, fp)\n",
    "print(len(adv_imgs[0]))\n",
    "#x = adv_imgs[1]\n",
    "#y = x[800]\n",
    "#plt.imshow(y.reshape(28, 28), cmap='Greys')\n",
    "#prb = generate_pd(training_data[1][0]*100)\n",
    "mean_imgs = mean_image(training_data)\n",
    "\n",
    "'''success = 0\n",
    "for i in range(10):\n",
    "    for j in range(len(adv_imgs[i])):\n",
    "        res = adv_imgs[i][j]\n",
    "        res = torch.Tensor(res).reshape(1, 1, 28, 28)\n",
    "        output = model(res)\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "\n",
    "        if pred == i:\n",
    "            success += 1\n",
    "\n",
    "print((success/ 40000) * 100)\n",
    "#print(pred)\n",
    "res = res.detach().numpy()\n",
    "#plt.imshow(res.reshape(28, 28), cmap=\"Greys\")\n",
    "#plt.show()\n",
    "'''\n",
    "\n",
    "'''images = []\n",
    "for i in range(10):\n",
    "    images.append(mean_imgs[i].reshape(28, 28))\n",
    "show_images(images)\n",
    "'''\n",
    "\n",
    "'''fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "ax1.scatter(tr_l, np.zeros((len(tr_l))), s=10, c='b', marker=\"s\", label='train')\n",
    "ax1.scatter(ad_l, np.ones((len(ad_l))), s=10, c='r', marker=\"o\", label='adversarial')\n",
    "plt.legend(loc='upper left');\n",
    "plt.show()\n",
    "'''    \n",
    "\n",
    "#Calculating threshold\n",
    "#min_thr = min_thr_calc(adv_imgs, mean_imgs, kl_calc) \n",
    "#print(ac_calc(test_data, training_data, adv_imgs, mean_imgs, min_thr, kl_calc))\n",
    "#print(ac_calc(test_data, training_data, adv_imgs, mean_imgs, js_calc))\n",
    "\n",
    "#min_thr = min_thr_calc(adv_imgs, mean_imgs, js_calc) \n",
    "#print(ac_calc(test_data, training_data, adv_imgs, mean_imgs, min_thr, js_calc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if __name__ == '__main__':\n",
    " #   main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            x         x2          x3  y\n",
      "0    4.417425  19.513644   86.200060  1\n",
      "1    8.120032  65.934926  535.393729  0\n",
      "2    3.682518  13.560940   49.938410  1\n",
      "3    3.481755  12.122621   42.207999  1\n",
      "4    8.121498  65.958731  535.683706  0\n",
      "5    1.232996   1.520280    1.874499  1\n",
      "6    7.471950  55.830037  417.159246  0\n",
      "7    7.345804  53.960835  396.385710  0\n",
      "8    5.975115  35.702005  213.323599  0\n",
      "9    2.556791   6.537179   16.714200  1\n",
      "10   4.417425  19.513644   86.200060  1\n",
      "11   6.825169  46.582936  317.936428  0\n",
      "12   7.524794  56.622531  426.072901  0\n",
      "13   8.615552  74.227743  639.513007  0\n",
      "14   7.975472  63.608159  507.305111  0\n",
      "15   6.907554  47.714306  329.589163  0\n",
      "16   7.208144  51.957344  374.516036  0\n",
      "17   7.280119  53.000134  385.847283  0\n",
      "18   2.893810   8.374138   24.233168  1\n",
      "19   2.556791   6.537179   16.714200  1\n",
      "20   7.047656  49.669451  350.053186  0\n",
      "21   2.076653   4.312489    8.955545  1\n",
      "22   3.521085  12.398040   43.654552  1\n",
      "23   2.075072   4.305922    8.935097  1\n",
      "24   5.322414  28.328094  150.773849  0\n",
      "25   3.630968  13.183929   47.870427  1\n",
      "26   3.595469  12.927397   46.480056  1\n",
      "27   6.908442  47.726567  329.716210  0\n",
      "28   8.448634  71.379422  603.058637  0\n",
      "29   8.508363  72.392249  615.939569  0\n",
      "..        ...        ...         ... ..\n",
      "970  2.537676   6.439800   16.342127  1\n",
      "971  6.932062  48.053489  333.109779  0\n",
      "972  7.431874  55.232753  410.482866  0\n",
      "973  2.560597   6.556655   16.788947  1\n",
      "974  7.608519  57.889560  440.453807  0\n",
      "975  5.166480  26.692517  137.906359  0\n",
      "976  3.678830  13.533787   49.788496  1\n",
      "977  6.848032  46.895545  321.142202  0\n",
      "978  3.049210   9.297684   28.350597  1\n",
      "979  9.256989  85.691843  793.248431  0\n",
      "980  6.996450  48.950317  342.478456  0\n",
      "981  4.417425  19.513644   86.200060  1\n",
      "982  9.800968  96.058974  941.470925  0\n",
      "983  1.219927   1.488222    1.815523  1\n",
      "984  7.173137  51.453890  369.085790  0\n",
      "985  8.319029  69.206245  575.728764  0\n",
      "986  5.624647  31.636654  177.945015  0\n",
      "987  2.376418   5.647361   13.420489  1\n",
      "988  7.827666  61.272359  479.619573  0\n",
      "989  1.223601   1.497200    1.831976  1\n",
      "990  2.893810   8.374138   24.233168  1\n",
      "991  4.405883  19.411804   85.526137  1\n",
      "992  2.118871   4.489616    9.512918  1\n",
      "993  2.376418   5.647361   13.420489  1\n",
      "994  6.661291  44.372798  295.580125  0\n",
      "995  7.519153  56.537665  425.115365  0\n",
      "996  6.029398  36.353644  219.190601  0\n",
      "997  7.993707  63.899353  510.792707  0\n",
      "998  7.500854  56.262811  422.019129  0\n",
      "999  8.347737  69.684710  581.709621  0\n",
      "\n",
      "[1000 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "idx_l = gn_idx_list(training_data)\n",
    "tr_l = []\n",
    "ad_l = []\n",
    "for j in range(10):\n",
    "    lst = idx_l[j]\n",
    "    for i in range(4000):\n",
    "        ind = lst[i]\n",
    "        tr_l.append(js_calc(training_data[ind][0], mean_imgs[j]))\n",
    "    for i in range(4000):\n",
    "        ad_l.append(js_calc(adv_imgs[j][i], mean_imgs[j]))\n",
    "        \n",
    "y = [0]*len(ad_l) + [1]*len(tr_l)\n",
    "x = ad_l + tr_l\n",
    "x2 = [i**2 for i in x]\n",
    "x3 = [i**3 for i in x]\n",
    "data = {'x': x, 'x2': x2, 'x3': x3, 'y': y}\n",
    "df = pd.DataFrame(data)\n",
    "df = df.sample(frac=1).reset_index(drop=True)                   \n",
    "n_df = df[['x', 'x2', 'x3']]\n",
    "normalized_df = (n_df - n_df.mean()) / n_df.std()\n",
    "normalized_df['y'] = df['y']\n",
    "\n",
    "print(df.head(1000))\n",
    "\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Create an instance of Logistic Regression Classifier and fit the data.\n",
    "logreg.fit(normalized_df[['x', 'x2', 'x3']][:60000], normalized_df['y'][:60000])\n",
    "\n",
    "res = logreg.predict(normalized_df[['x', 'x2', 'x3']][60000:])\n",
    "Y = np.asarray(normalized_df['y'][60000:])\n",
    "acc = (np.sum(Y == res) / 20000)*100\n",
    "                   \n",
    "                   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.91\n"
     ]
    }
   ],
   "source": [
    "Y = np.asarray(normalized_df['y'][60000:])\n",
    "acc = (np.sum(Y == res) / 20000)*100\n",
    "print(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "ax1.scatter(tr_l, np.zeros((len(tr_l))), s=10, c='b', marker=\"s\", label='train')\n",
    "ax1.scatter(ad_l, np.ones((len(ad_l))), s=10, c='r', marker=\"o\", label='adversarial')\n",
    "plt.legend(loc='upper left');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
