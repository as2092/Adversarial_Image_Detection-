{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "from network.cifar10_cnn_net import cifar10_cnn_net\n",
    "import utils.mnist_loader as mnist_loader\n",
    "import utils.mnistf_loader as mnistf_loader\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import argparse\n",
    "from numpy import ma\n",
    "import scipy\n",
    "import os.path\n",
    "import network.ann_net as ann_net\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "\n",
    "def gn_adv(args, model, device, target):\n",
    "    \"\"\"\n",
    "\n",
    "    :param args:\n",
    "    :param model:\n",
    "    :param device:\n",
    "    :param target: label for which adv image is to be generated\n",
    "    :return: adv image\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    target = torch.Tensor([target]).long()\n",
    "    data = torch.rand((1, 1, 28, 28), requires_grad=True, device=device)\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    optimizer = optim.SGD([data], lr=1, momentum=args.momentum)\n",
    "\n",
    "    for itr in range(50):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        #print(loss)\n",
    "        optimizer.step()\n",
    "\n",
    "    return torch.squeeze(data).detach().cpu().numpy()\n",
    "\n",
    "\n",
    "def sneaky_adv(args, model, device, img, target, lmbd):\n",
    "    \"\"\"\n",
    "    :param img: image whose alike image to be constructed\n",
    "    :param target: label that network should output\n",
    "    :return: image that looks like img and network output is target\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    data = torch.rand((1, 1, 28, 28), device=device, requires_grad=True)\n",
    "    target = torch.Tensor([target]).long()\n",
    "    img = torch.Tensor(img).view((1, 1, 28, 28))\n",
    "    img, target, data = img.to(device), target.to(device), data.to(device)\n",
    "    optimizer = optim.SGD([data], lr=0.4, momentum=args.momentum)\n",
    "\n",
    "    for itr in range(1500):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target) + lmbd*torch.norm((img-data), 2)\n",
    "        loss.backward()\n",
    "        #print(loss)\n",
    "        optimizer.step()\n",
    "\n",
    "    return torch.squeeze(data).detach().cpu().numpy()\n",
    "    \n",
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                       100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "\n",
    "def test(args, model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "\n",
    "def kld(model, actual):\n",
    "    \"\"\"\n",
    "    model : its the array that is input to the network\n",
    "    actual : image corresponding to the network output\n",
    "    return: KL divergence between two prob distributions\n",
    "    \"\"\"\n",
    "    model = np.asarray(list(model) + [0 for i in range(255 - len(model))])\n",
    "    actual = np.asarray(list(actual) + [0 for i in range(255 - len(actual))])\n",
    "    k = ((model * np.log(model)) - (model * np.log(actual))).sum()\n",
    "    print(k)\n",
    "    # k = (model * ma.log(model/actual)).sum()\n",
    "\n",
    "    return k\n",
    "\n",
    "\n",
    "def mean_image(tr_data):\n",
    "    \"\"\"\n",
    "\n",
    "    :param tr_data: input mnist data\n",
    "    :return: mean images for each class\n",
    "    \"\"\"'''\n",
    "    val = {}\n",
    "    for i in range(10):\n",
    "        mat = []\n",
    "        for r in range(len(tr_data)):\n",
    "            if tr_data[r][1][i] == 1:\n",
    "                x = tr_data[r][0]\n",
    "                mat.append(np.asarray(x))\n",
    "        val[i] = np.mean(mat, axis=0) * (100)\n",
    "\n",
    "    return val'''\n",
    "    #tr_data = torch.tensor(tr_data)\n",
    "    val = {}\n",
    "    for i in range(10):\n",
    "        val[i] = []\n",
    "    \n",
    "    for i in range(len(tr_data)):\n",
    "        val[tr_data[i][1]].append(np.asarray(tr_data[i][0]))\n",
    "    \n",
    "        \n",
    "    for i in range(10):\n",
    "        val[i] = np.asarray(val[i]).reshape((-1, 3072))\n",
    "        val[i] = np.mean(val[i], axis=0)\n",
    "        \n",
    "    return val    \n",
    "\n",
    "\n",
    "def gn_idx_list(training_data):\n",
    "    idx_list = {}\n",
    "    for i in range(10):\n",
    "        idx_list[i] = []\n",
    "    for i in range(len(training_data)):\n",
    "        idx_list[training_data[i][1]].append(i)\n",
    "\n",
    "    return idx_list    \n",
    "\n",
    "\n",
    "\n",
    "def gn_adv_imgs(args, model, device, training_data):\n",
    "    \"\"\"\n",
    "\n",
    "    :param training_data:\n",
    "    :return: 100 adversarial images\n",
    "    \"\"\"\n",
    "    gn = {}\n",
    "    \"\"\"idx_list = []\n",
    "    for i in range(10):\n",
    "        idx = np.random.randint(0, 8000)\n",
    "        while training_data[idx][1][i] != 1:\n",
    "            idx += 1\n",
    "        idx_list.append(idx)\"\"\"\n",
    "    idx_list = gn_idx_list(training_data)\n",
    "\n",
    "    for g in range(10):\n",
    "        gl = []\n",
    "        print(g)\n",
    "        for v in range(10):\n",
    "            if g != v:\n",
    "                for i in range(400):\n",
    "                    idx = idx_list[v][i]\n",
    "                    gl.append(sneaky_adv(args, model, device, training_data[idx][0], g, 0.4))\n",
    "            else:\n",
    "                for i in range(400):\n",
    "                    idx = idx_list[v][i]\n",
    "                    gl.append(gn_adv(args, model, device, g))\n",
    "        gn[g] = gl\n",
    "\n",
    "    return gn\n",
    "\n",
    "\n",
    "def gn_pd_imgs(adv_imgs):\n",
    "    \"\"\"\n",
    "    adv_imgs: a dictionary with keys as the classes and corresponding adv images as values\n",
    "    returns gn_pd : a dictionary with keys as classes and corresponding prob. distribution of adv images\n",
    "    \"\"\"\n",
    "    gn_pd = {}\n",
    "    for k, v in adv_imgs.items():\n",
    "        bin_y = []\n",
    "\n",
    "        for i in range(len(v)):\n",
    "            bin_y.append(generate_pd(v[i]))\n",
    "\n",
    "        gn_pd[k] = bin_y\n",
    "\n",
    "    return gn_pd\n",
    "\n",
    "\n",
    "def mean_pd(mean_imgs):\n",
    "    \"\"\"\n",
    "    val: a dictionary with keys as the classes and corresponding mean images as values\n",
    "    returns val_pd : a dictionary with keys as classes and corresponding prob. distribution of mean images\n",
    "    \"\"\"\n",
    "    val_pd = {}\n",
    "    for k, v in mean_imgs.items():\n",
    "        # print(k)\n",
    "        # print(len(v))\n",
    "        val_pd[k] = generate_pd(v)\n",
    "\n",
    "    return val_pd\n",
    "\n",
    "\n",
    "def generate_pd(img, patch_size=28):\n",
    "    \"\"\"\n",
    "    img: an image\n",
    "    returns pd : prob distribution of intensities in img\n",
    "    \"\"\"\n",
    "    \n",
    "    if img.max() - img.min() == 0:\n",
    "        img = np.zeros((patch_size, patch_size))\n",
    "    else:\n",
    "        img = ((img - img.min()) * (1 / (img.max() - img.min()) * 255).astype('uint8'))\n",
    "    img = np.floor(img)\n",
    "    img = img.reshape((-1, patch_size**2))\n",
    "    img = img.astype('int64')\n",
    "    bin_m = np.bincount(img[0])\n",
    "    l1 = list(bin_m)\n",
    "    l2 = [0]*(256 - len(bin_m))\n",
    "    bin_m = l1 + l2\n",
    "    bin_m = [x if x != 0 else 0.0001 for x in bin_m] \n",
    "    bin_m = bin_m / sum(bin_m)\n",
    "    # making sure to have len of list 255\n",
    "    pd = np.asarray(bin_m)\n",
    "    #pd = [x if x != 0 else 0.0001 for x in pd]  # to avoid divide by zero in KLD\n",
    "\n",
    "    return pd\n",
    "\n",
    "\n",
    "\n",
    "def kl_calc(adv_im, mean_im):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    adv_im = np.asarray(adv_im).reshape(28, 28)\n",
    "    mean_im = np.asarray(mean_im).reshape(28, 28)\n",
    "    k_sum = 0\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            s_arr = adv_im[i: i + 7, i: i + 7]\n",
    "            p = generate_pd(s_arr, 7)\n",
    "            # mean image pd\n",
    "            ms_arr = mean_im[i: i + 7, i: i + 7]\n",
    "            q = generate_pd(ms_arr, 7)\n",
    "            k_sum += scipy.stats.entropy(p, q)\n",
    "\n",
    "    return k_sum\n",
    "\n",
    "def js_calc(adv_im, mean_im):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    adv_im = np.asarray(adv_im).reshape(28, 28)\n",
    "    mean_im = np.asarray(mean_im).reshape(28, 28)\n",
    "    k_sum = 0\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            s_arr = adv_im[i: i + 7, j: j + 7]\n",
    "            p = generate_pd(s_arr, 7)\n",
    "            # mean image pd\n",
    "            ms_arr = mean_im[i: i + 7, j: j + 7]\n",
    "            q = generate_pd(ms_arr, 7)\n",
    "            r = (p + q)/ 2\n",
    "            k_sum += (scipy.stats.entropy(p, r) / 2) + (scipy.stats.entropy(q, r) / 2)\n",
    "\n",
    "    return k_sum\n",
    "\n",
    "def ac_calc(test_data, training_data, adv_imgs, mean_imgs, min_thr, fun):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    min_thr = min_thr_calc(adv_imgs, mean_imgs, fun)\n",
    "    \n",
    "    success = 0\n",
    "    tmp = 1000\n",
    "    for i in range(len(adv_imgs)):\n",
    "        f = adv_imgs[i]\n",
    "        for j in range(len(f)):\n",
    "            tmp = fun(f[j],mean_imgs[i])\n",
    "            if tmp >= min_thr[i]:\n",
    "                success += 1\n",
    "\n",
    "    #print((success/40000) * 100)\n",
    "    #success = 0\n",
    "    tmp = 1000\n",
    "    for i in range(400):\n",
    "        label = np.argmax(test_data[i][1])\n",
    "        f = np.asarray(test_data[i][0]).reshape((-1, 784))\n",
    "        tmp = fun(f, mean_imgs[label])\n",
    "        if tmp < min_thr[label]:\n",
    "            success += 1\n",
    "    '''\n",
    "    for i in range(len(training_data)):\n",
    "        label = np.argmax(training_data[i][1])\n",
    "        f = np.asarray(training_data[i][0]).reshape((-1, 784))\n",
    "        tmp = fun(f, mean_imgs[label])\n",
    "        if tmp < min_thr[label]:\n",
    "            success += 1\n",
    "'''\n",
    "    return (success/(len(adv_imgs)*len(adv_imgs[0]) + 400)* 100)\n",
    "\n",
    "\n",
    "def min_thr_calc(adv_imgs, mean_imgs, fun):\n",
    "    \"\"\"\n",
    "    # each class contain 4000 adversarial examples\n",
    "    # 400 uniformly chosen samples out of 4000 are used for min_thr calc\n",
    "    return: list containing min_thr for each of the 10 classes\n",
    "    \"\"\"\n",
    "    min_thr = []\n",
    "    ind = np.random.randint(40, size=4)\n",
    "    tmp = 1000\n",
    "    for i in range(len(adv_imgs)):\n",
    "        f = adv_imgs[i]\n",
    "        for j in ind:\n",
    "            tmp = min(tmp, fun(f[j], mean_imgs[i]))\n",
    "        if (tmp == 1000):\n",
    "            print(i)\n",
    "        min_thr.append(tmp) \n",
    "        tmp =1000\n",
    "    \n",
    "    return min_thr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'fig = plt.figure()\\nax1 = fig.add_subplot(111)\\n\\nax1.scatter(tr_l, np.zeros((len(tr_l))), s=10, c=\\'b\\', marker=\"s\", label=\\'train\\')\\nax1.scatter(ad_l, np.ones((len(ad_l))), s=10, c=\\'r\\', marker=\"o\", label=\\'adversarial\\')\\nplt.legend(loc=\\'upper left\\');\\nplt.show()\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#def main():\n",
    "    # Training settings\n",
    "parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n",
    "parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n",
    "                    help='input batch size for training (default: 64)')\n",
    "parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\n",
    "                    help='input batch size for testing (default: 1000)')\n",
    "parser.add_argument('--epochs', type=int, default=30, metavar='N',\n",
    "                    help='number of epochs to train (default: 10)')\n",
    "parser.add_argument('--lr', type=float, default=0.1, metavar='LR',\n",
    "                    help='learning rate (default: 0.01)')\n",
    "parser.add_argument('--momentum', type=float, default=0.5, metavar='M',\n",
    "                    help='SGD momentum (default: 0.5)')\n",
    "parser.add_argument('--no-cuda', action='store_true', default=True,\n",
    "                    help='disables CUDA training')\n",
    "parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                    help='random seed (default: 1)')\n",
    "parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
    "                    help='how many batches to wait before logging training status')\n",
    "\n",
    "parser.add_argument('--save-model', action='store_true', default=False,\n",
    "                    help='For Saving the current Model')\n",
    "args = parser.parse_args([])\n",
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10('data/cifar10', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10('data/cifar10', train=False, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])),\n",
    "    batch_size=args.test_batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "model = cifar10_cnn_net().to(device)\n",
    "optimizer = None\n",
    "\n",
    "training_data =  datasets.CIFAR10('data/cifar10', train=True)\n",
    "\n",
    "mean_imgs = mean_image(training_data)\n",
    "# for training of the cnn-network\n",
    "'''if (args.save_model):\n",
    "    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        train(args, model, device, train_loader, optimizer, epoch)\n",
    "        test(args, model, device, test_loader)\n",
    "\n",
    "    torch.save(model.state_dict(), \"cifar10_cnn.pt\")\n",
    "\n",
    "# to generate adversarial images from trained network\n",
    "model.load_state_dict(torch.load(\"cifar10_cnn.pt\"))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "for target in range(10):\n",
    "    res = gn_adv(args, model, device, target)\n",
    "    print(res.shape)\n",
    "    res = torch.Tensor(res).reshape(1, 1, 28, 28)\n",
    "    output = model(res)\n",
    "    pred = output.argmax(dim=1, keepdim=True)\n",
    "    print(pred)\n",
    "    \n",
    "''''''# generate sneaky_adversarial images test code\n",
    "target_label = 1\n",
    "target_img = 4\n",
    "idx = np.random.randint(0, 8000)\n",
    "while training_data[idx][1][target_img] != 1:\n",
    "    idx += 1\n",
    "#training_data[idx][0]\n",
    "res = sneaky_adv(args, model, device, training_data[idx][0], target_label, 0.3)\n",
    "plt.imshow(res.reshape(28, 28), cmap=\"Greys\")\n",
    "res = torch.Tensor(res).reshape(1, 1, 28, 28)\n",
    "output = model(res)\n",
    "pred = output.argmax(dim=1, keepdim=True)\n",
    "print(pred)\n",
    "\n",
    "# generate adversarial images\n",
    "if os.path.exists('adv_imgs_mnistf.pkl'):\n",
    "    print(\"file_exist\")\n",
    "    with open('adv_imgs_imgs_mnistf.pkl', 'rb') as f:\n",
    "        adv_imgs = pickle.load(f)\n",
    "else:\n",
    "    adv_imgs = gn_adv_imgs(args, model, device, training_data)\n",
    "    with open(\"adv_imgs_mnistf.pkl\", \"wb\") as fp:   #Pickling\n",
    "        pickle.dump(adv_imgs, fp)\n",
    "print(len(adv_imgs[0]))\n",
    "#x = adv_imgs[1]\n",
    "#y = x[800]\n",
    "#plt.imshow(y.reshape(28, 28), cmap='Greys')\n",
    "#prb = generate_pd(training_data[1][0]*100)'''\n",
    "\n",
    "\n",
    "'''success = 0\n",
    "for i in range(10):\n",
    "    for j in range(len(adv_imgs[i])):\n",
    "        res = adv_imgs[i][j]\n",
    "        res = torch.Tensor(res).reshape(1, 1, 28, 28)\n",
    "        output = model(res)\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "\n",
    "        if pred == i:\n",
    "            success += 1\n",
    "\n",
    "print((success/ 40000) * 100)\n",
    "#print(pred)\n",
    "res = res.detach().numpy()\n",
    "#plt.imshow(res.reshape(28, 28), cmap=\"Greys\")\n",
    "#plt.show()\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "'''mean_imgs = mean_image(training_data)\n",
    "#y = mean_imgs[2]\n",
    "#plt.imshow(y.reshape(28, 28), cmap='Greys')\n",
    "idx_l = gn_idx_list(training_data)\n",
    "'''\n",
    "\n",
    "'''fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "ax1.scatter(tr_l, np.zeros((len(tr_l))), s=10, c='b', marker=\"s\", label='train')\n",
    "ax1.scatter(ad_l, np.ones((len(ad_l))), s=10, c='r', marker=\"o\", label='adversarial')\n",
    "plt.legend(loc='upper left');\n",
    "plt.show()\n",
    "'''    \n",
    "\n",
    "#Calculating threshold\n",
    "#min_thr = min_thr_calc(adv_imgs, mean_imgs, kl_calc) \n",
    "#print(ac_calc(test_data, training_data, adv_imgs, mean_imgs, min_thr, kl_calc))\n",
    "#print(ac_calc(test_data, training_data, adv_imgs, mean_imgs, js_calc))\n",
    "\n",
    "#min_thr = min_thr_calc(adv_imgs, mean_imgs, js_calc) \n",
    "#print(ac_calc(test_data, training_data, adv_imgs, mean_imgs, min_thr, js_calc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[136 138 135]\n",
      "  [136 137 135]\n",
      "  [137 138 136]\n",
      "  ..., \n",
      "  [137 138 136]\n",
      "  [136 138 135]\n",
      "  [135 137 135]]\n",
      "\n",
      " [[135 136 134]\n",
      "  [135 136 133]\n",
      "  [136 137 134]\n",
      "  ..., \n",
      "  [135 137 134]\n",
      "  [134 136 133]\n",
      "  [133 135 133]]\n",
      "\n",
      " [[133 134 131]\n",
      "  [133 134 131]\n",
      "  [134 134 131]\n",
      "  ..., \n",
      "  [133 135 131]\n",
      "  [133 134 131]\n",
      "  [132 133 130]]\n",
      "\n",
      " ..., \n",
      " [[132 130 125]\n",
      "  [128 126 121]\n",
      "  [124 122 116]\n",
      "  ..., \n",
      "  [126 124 119]\n",
      "  [130 127 122]\n",
      "  [132 130 125]]\n",
      "\n",
      " [[133 131 126]\n",
      "  [130 128 123]\n",
      "  [128 126 120]\n",
      "  ..., \n",
      "  [130 127 122]\n",
      "  [131 129 124]\n",
      "  [133 131 126]]\n",
      "\n",
      " [[134 132 127]\n",
      "  [132 130 125]\n",
      "  [131 129 124]\n",
      "  ..., \n",
      "  [132 129 124]\n",
      "  [132 130 125]\n",
      "  [133 131 126]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x249cb80c6d8>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "im = np.asarray(mean_imgs[1].reshape(32, 32, 3), dtype=\"uint8\")\n",
    "print(im)\n",
    "img = Image.fromarray(im)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3072)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = mean_imgs[5].reshape((-1, 32*32*3))\n",
    "m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca(im_data):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    im = np.asarray(im_data[:100])\n",
    "    im = im.reshape((-1, 3072))\n",
    "    \n",
    "    face_db = im.T\n",
    "    \n",
    "    M = np.mean(face_db, axis=1) #mean calculation\n",
    "    M = M.reshape(3072, 1)\n",
    "    delta = face_db - M  #mean zero images\n",
    "    \n",
    "    #covariance of dimension pxp\n",
    "    c = np.cov(delta.T) \n",
    "    \n",
    "    eigen_values, eigen_vectors = LA.eig(c)\n",
    "    feature_vector = eigen_vectors\n",
    "    \n",
    "    eigen_face = np.dot(delta, feature_vector)\n",
    "    \n",
    "    #eigen_projection = np.dot(eigen_face.T, delta)\n",
    "    print(eigen_face.shape)\n",
    "    \n",
    "    #mean eigen face for each class\n",
    "    #mean_eig = np.mean(eigen_face, axis=0)\n",
    "    #mean_eig = mean_eig.real\n",
    "    \n",
    "    #plt.imshow(mean_eig.reshape(28, 28), cmap='Greys')\n",
    "    #return mean_eig\n",
    "    return eigen_face\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3072, 100)\n",
      "(3072, 100)\n",
      "(3072, 100)\n",
      "(3072, 100)\n",
      "(3072, 100)\n",
      "(3072, 100)\n",
      "(3072, 100)\n",
      "(3072, 100)\n",
      "(3072, 100)\n",
      "(3072, 100)\n"
     ]
    }
   ],
   "source": [
    "def eigen_image(tr_data):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    '''eig_im = {}\n",
    "    for i in range(10):\n",
    "        mat = []\n",
    "        for r in range(len(tr_data)):\n",
    "            if tr_data[r][1][i] == 1:\n",
    "                x = tr_data[r][0]\n",
    "                mat.append(np.asarray(x))\n",
    "        eig_im[i] = pca(mat)\n",
    "        \n",
    "    return eig_im'''\n",
    "\n",
    "    val = {}\n",
    "    eig_im = {}\n",
    "    for i in range(10):\n",
    "        val[i] = []\n",
    "    \n",
    "    for i in range(len(tr_data)):\n",
    "        val[tr_data[i][1]].append(np.asarray(tr_data[i][0]))\n",
    "        \n",
    "    for i in range(10):\n",
    "        eig_im[i] = pca(val[i])\n",
    "        \n",
    "    return eig_im    \n",
    "\n",
    "\n",
    "eig_images = eigen_image(training_data)\n",
    "#plt.imshow(eig_images[3].reshape(28, 28), cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.mean(eig_images[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  3   4   6]\n",
      "  [  6   5   7]\n",
      "  [  6   6   7]\n",
      "  ..., \n",
      "  [  7   5   5]\n",
      "  [  7   5   6]\n",
      "  [  6   4   5]]\n",
      "\n",
      " [[  4   5   6]\n",
      "  [  7   6   7]\n",
      "  [  7   6   7]\n",
      "  ..., \n",
      "  [  7   5   5]\n",
      "  [  7   5   6]\n",
      "  [  6   5   5]]\n",
      "\n",
      " [[  4   4   6]\n",
      "  [  7   6   7]\n",
      "  [  7   6   6]\n",
      "  ..., \n",
      "  [  9   6   6]\n",
      "  [  8   6   6]\n",
      "  [  7   5   5]]\n",
      "\n",
      " ..., \n",
      " [[253 252 253]\n",
      "  [254 254 254]\n",
      "  [253 253 253]\n",
      "  ..., \n",
      "  [255 254 253]\n",
      "  [  0 255 255]\n",
      "  [254 254 254]]\n",
      "\n",
      " [[255 254 255]\n",
      "  [  0 255 255]\n",
      "  [254 254 255]\n",
      "  ..., \n",
      "  [  0 255 255]\n",
      "  [  0 255 255]\n",
      "  [255 254 254]]\n",
      "\n",
      " [[255 253 253]\n",
      "  [254 252 252]\n",
      "  [253 253 253]\n",
      "  ..., \n",
      "  [254 253 253]\n",
      "  [255 254 253]\n",
      "  [  0 255 255]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x249c94542e8>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "mi = np.asarray(m.reshape(32, 32, 3), dtype=\"uint8\")\n",
    "print(mi)\n",
    "mg = Image.fromarray(mi)\n",
    "plt.imshow(mg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_l = []\n",
    "ad_l = []\n",
    "for j in range(10):\n",
    "    lst = idx_l[j]\n",
    "    for i in range(4000):\n",
    "        ind = lst[i]\n",
    "        tr_l.append(js_calc(training_data[ind][0], mean_imgs[j]))\n",
    "    for i in range(4000):\n",
    "        ad_l.append(js_calc(adv_imgs[j][i], mean_imgs[j]))\n",
    "        \n",
    "y = [0]*len(ad_l) + [1]*len(tr_l)\n",
    "x = ad_l + tr_l\n",
    "x2 = [i**2 for i in x]\n",
    "x3 = [i**3 for i in x]\n",
    "data = {'x': x, 'x2': x2, 'x3': x3, 'y': y}\n",
    "df = pd.DataFrame(data)\n",
    "df = df.sample(frac=1).reset_index(drop=True)                   \n",
    "n_df = df[['x', 'x2', 'x3']]\n",
    "normalized_df = (n_df - n_df.mean()) / n_df.std()\n",
    "normalized_df['y'] = df['y']\n",
    "\n",
    "print(df.head(1000))\n",
    "\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Create an instance of Logistic Regression Classifier and fit the data.\n",
    "logreg.fit(normalized_df[['x', 'x2', 'x3']][:60000], normalized_df['y'][:60000])\n",
    "\n",
    "res = logreg.predict(normalized_df[['x', 'x2', 'x3']][60000:])\n",
    "Y = np.asarray(normalized_df['y'][60000:])\n",
    "acc = (np.sum(Y == res) / 20000)*100\n",
    "                   \n",
    "                   \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
